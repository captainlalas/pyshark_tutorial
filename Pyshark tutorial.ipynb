{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737c1480",
   "metadata": {},
   "source": [
    "## Welcome to our Pyspark tutorial\n",
    "\n",
    "### 1. Intalling pyspark and reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91519145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex</td>\n",
       "      <td>25</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iannis</td>\n",
       "      <td>22</td>\n",
       "      <td>Pro Tennis</td>\n",
       "      <td>9,345,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William</td>\n",
       "      <td>26</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>1,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald</td>\n",
       "      <td>30</td>\n",
       "      <td>IT</td>\n",
       "      <td>85,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cedric</td>\n",
       "      <td>31</td>\n",
       "      <td>Marketing Manager</td>\n",
       "      <td>90,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mathew</td>\n",
       "      <td>27</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>78,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age         Profession     Income\n",
       "0     Alex   25     Data Scientist    120,000\n",
       "1   Iannis   22         Pro Tennis   9,345,00\n",
       "2  William   26       Entrepreneur  1,400,000\n",
       "3   Donald   30                 IT     85,000\n",
       "4   Cedric   31  Marketing Manager     90,000\n",
       "5   Mathew   27         Accountant     78,000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After installing pyspark we will import it and start playing with\n",
    "# Please install pyspark first if it is not yet done with the command \"pip install pyspark\"\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"name.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50028d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb09fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a4b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x275c92b5f70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eaeabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3a0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset with the first row as header\n",
    "df_pyspark = spark.read.option('header','true').csv('name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a955d76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Profession: string (nullable = true)\n",
      " |-- Income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_pyspark.head(4)\n",
    "# And now we can check the data types\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc0a97",
   "metadata": {},
   "source": [
    "### 2. Pyspark Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7cc3699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Profession: string (nullable = true)\n",
      " |-- Income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's read the dataset with the appropriate data type for each columns\n",
    "df_pyspark = spark.read.csv('name.csv', header=True, inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4816385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Profession', 'Income']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2effd972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|   Alex| 25|\n",
      "| Iannis| 22|\n",
      "|William| 26|\n",
      "| Donald| 30|\n",
      "| Cedric| 31|\n",
      "| Mathew| 27|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How to select a specific column or a list of columns with the \"select\" operation\n",
    "df_pyspark.select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06cd964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+----------+----------+\n",
      "|summary|   Name|               Age|Profession|    Income|\n",
      "+-------+-------+------------------+----------+----------+\n",
      "|  count|      6|                 6|         6|         6|\n",
      "|   mean|   NULL|26.833333333333332|      NULL|      NULL|\n",
      "| stddev|   NULL|3.3115957885386114|      NULL|      NULL|\n",
      "|    min|   Alex|                22|Accountant|$1,400,000|\n",
      "|    max|William|                31|Pro Tennis|   $90,000|\n",
      "+-------+-------+------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the data types and describe summary\n",
    "df_pyspark.dtypes\n",
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7f2e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----------------+----------+----------+\n",
      "|   Name|Age|       Profession|    Income|Experience|\n",
      "+-------+---+-----------------+----------+----------+\n",
      "|   Alex| 25|   Data Scientist|  $120,000|         4|\n",
      "| Iannis| 22|       Pro Tennis|$9,345,000|         5|\n",
      "|William| 26|     Entrepreneur|$1,400,000|         2|\n",
      "| Donald| 30|               IT|   $85,000|         3|\n",
      "| Cedric| 31|Marketing Manager|   $90,000|         4|\n",
      "| Mathew| 27|       Accountant|   $78,000|         3|\n",
      "+-------+---+-----------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Adding a new column in dataframe, could be also done by aggregating an existing col\n",
    "from pyspark.sql.functions import when, lit\n",
    "exp_list = [4, 5, 2, 6, 4, 3]\n",
    "new_df = df_pyspark.withColumn(\"Experience\",\n",
    "                              when((df_pyspark.Name == \"Alex\") | (df_pyspark.Name == \"Cedric\"), lit(4)).\n",
    "                               when((df_pyspark.Name == \"Iannis\"), lit(5)).\n",
    "                               when((df_pyspark.Name == \"William\"), lit(2)).\n",
    "                               when((df_pyspark.Name == \"Donald\") | (df_pyspark.Name == \"Mathew\"), lit(3)))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7d155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84558e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09be32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275e637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc012a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "550693b6",
   "metadata": {},
   "source": [
    "&copy; Please note that this notebook was built following the instruction of the [freeCodeCamp.org Pyshark tutorial on YouTube](https://www.youtube.com/watch?v=_C8kWso4ne4). The dataset belongs to the owner of the notebook and some lines of code were changed on purpose for a better hands-on experience of Pyshark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b740c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
